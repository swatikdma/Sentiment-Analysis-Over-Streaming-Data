{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SentiDDM",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "FeUiCl7HxzyY"
      },
      "source": [
        "import pyspark\n",
        "from __future__ import print_function\n",
        "from pyspark import SparkContext\n",
        "from pyspark.streaming import StreamingContext"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qw8cOKXkyKEQ"
      },
      "source": [
        "import pyspark\n",
        "from pyspark.sql import *\n",
        "from pyspark.sql.types import *\n",
        "from pyspark.sql.functions import *\n",
        "from pyspark import SparkContext, SparkConf\n",
        "sc = SparkContext(appName = \"StreamingTwitterAnalysis\")\n",
        "sc.setLogLevel(\"ERROR\")\n",
        "ssc = StreamingContext(sc,10)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KMAbYrb_mtHb"
      },
      "source": [
        "# Machine learning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Feg7C_01nDTv"
      },
      "source": [
        "# importing required libraries\n",
        "import pyspark.ml.feature\n",
        "from pyspark import SparkContext\n",
        "from pyspark.sql.session import SparkSession\n",
        "from pyspark.streaming import StreamingContext\n",
        "import pyspark.sql.types as tp\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.feature import StringIndexer, VectorAssembler\n",
        "from pyspark.ml.feature import StopWordsRemover, Word2Vec, RegexTokenizer\n",
        "from pyspark.ml.classification import LogisticRegression\n",
        "from pyspark.sql import Row\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LBqiUt8kpRbW"
      },
      "source": [
        "## Reading the csv file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WCIxvDcnnDD0"
      },
      "source": [
        "spark = SparkSession(sc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TyecDEECol3e"
      },
      "source": [
        "my_schema = tp.StructType([\n",
        "  tp.StructField(name= 'id',          dataType= tp.IntegerType(),  nullable= True),\n",
        "  tp.StructField(name= 'label',       dataType= tp.IntegerType(),  nullable= True),\n",
        "  tp.StructField(name= 'tweet',       dataType= tp.StringType(),   nullable= True)\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RHspobfRooWG"
      },
      "source": [
        "my_data = spark.read.csv('/home/swati/Desktop/tweets.csv',\n",
        "                         schema=my_schema,\n",
        "                         header=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gQmhIp4fo78R"
      },
      "source": [
        "# view the data\n",
        "my_data.show(5)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rTmDj7gwo96x"
      },
      "source": [
        "# print the schema of the file\n",
        "my_data.printSchema()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eqkpe7rMpBrE"
      },
      "source": [
        "## Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S8I8bxOepAsn"
      },
      "source": [
        "# define stage 1: tokenize the tweet text    \n",
        "# stage_1 = RegexTokenizer(inputCol= 'tweet' , outputCol= 'tokens', pattern= '\\\\W')\n",
        "stage_1 = RegexTokenizer(pattern=r'(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)', inputCol='tweet', outputCol='tokens')\n",
        "# define stage 2: remove the stop words\n",
        "stage_2 = StopWordsRemover(inputCol= 'tokens', outputCol= 'filtered_words')\n",
        "# define stage 3: create a word vector of the size 100\n",
        "stage_3 = Word2Vec(inputCol= 'filtered_words', outputCol= 'vector', vectorSize= 100)\n",
        "# define stage 4: Logistic Regression Model\n",
        "model = LogisticRegression(featuresCol= 'vector', labelCol= 'label')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2eZrW_NIqk7O"
      },
      "source": [
        "# setup the pipeline\n",
        "pipeline = Pipeline(stages= [stage_1, stage_2, stage_3, model])\n",
        "\n",
        "# fit the pipeline model with the training data\n",
        "pipelineFit = pipeline.fit(my_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5yiWL6tZqtyw"
      },
      "source": [
        "# define a function to compute sentiments of the received tweets\n",
        "def get_prediction(tweet_text):\n",
        "\ttry:\n",
        "    # filter the tweets whose length is greater than 0\n",
        "\t\ttweet_text = tweet_text.filter(lambda x: len(x) > 0)\n",
        "    # create a dataframe with column name 'tweet' and each row will contain the tweet\n",
        "\t\trowRdd = tweet_text.map(lambda w: Row(tweet=w))\n",
        "    # create a spark dataframe\n",
        "\t\twordsDataFrame = spark.createDataFrame(rowRdd)\n",
        "    # transform the data using the pipeline and get the predicted sentiment\n",
        "\t\tpipelineFit.transform(wordsDataFrame).select('tweet','prediction').show()\n",
        "\texcept : \n",
        "\t\tprint('No data')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xye_SR2jzaQX"
      },
      "source": [
        "#Streaming Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yg4rvZYdzJmX"
      },
      "source": [
        "Setting LogLevel will not print warning messages\n",
        "\n",
        "Setting a batch interval of 10s"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x921yZA0yvMQ"
      },
      "source": [
        "socket_stream = ssc.socketTextStream(\"127.0.0.1\" , 6006 )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HXPr9Kf-z0Qb"
      },
      "source": [
        "All analysis will be done for 60 seconds for a window"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qwZRkH8FzntR"
      },
      "source": [
        "lines = socket_stream.window(60)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4sUn_nlAz6qd"
      },
      "source": [
        "# hashtags = lines.flatMap(lambda text : text.split('')).filter(lambda word : word.lower().startswith('#')).map(lambda word: (word.lower(),1)).reduceByKey(lambda a,b:a+b)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HnHaTajarIDf"
      },
      "source": [
        "# split the tweet text by a keyword 'TWEET_APP' so that we can identify which set of words is from a single tweet\n",
        "words = lines.flatMap(lambda line : line.split('TWEET_APP')).filter(lambda word : word.lower())\n",
        "\n",
        "# get the predicted sentiments for the tweets received\n",
        "words.foreachRDD(get_prediction)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TO5iI6KhKjR3"
      },
      "source": [
        "# author_count_sorted_dstream = hashtags.transform(lambda foo : foo.sortBy(lambda x: x[0].lower()).sortBy(lambda x:x[1],ascending=False))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XbU0EQs-LmwF"
      },
      "source": [
        "# author_count_sorted_dstream.pprint()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dyj5svG608S-"
      },
      "source": [
        "# lines.pprint()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B1OA0noew2RA"
      },
      "source": [
        "# Starting computations for all batches"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zq4IEUOrLypv"
      },
      "source": [
        "ssc.start()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bo3QxoLPL0aM"
      },
      "source": [
        "ssc.awaitTermination()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}